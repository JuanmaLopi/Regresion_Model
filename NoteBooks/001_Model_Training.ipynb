{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: R2 Score = 0.9392\n",
      "Ridge Regression: R2 Score = 0.9280\n",
      "Lasso Regression: R2 Score = 0.6092\n",
      "Elastic Net Regression: R2 Score = 0.6485\n",
      "K-Nearest Neighbors Regression: R2 Score = 0.8527\n",
      "Random Forest Regression: R2 Score = 0.8538\n",
      "XGBoost Regression: R2 Score = 0.8758\n",
      "\n",
      "Best model: Linear Regression with R2 Score = 0.9392\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Cargar los datos\n",
    "file_path = '../data/Model_Data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Realizar codificación one-hot para la columna 'Country'\n",
    "data = pd.get_dummies(data, columns=['Country'], drop_first=True)\n",
    "\n",
    "# Separar las características (X) y la variable objetivo (y)\n",
    "X = data.drop(columns=['Happiness Score'])\n",
    "y = data['Happiness Score']\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Definir los modelos a evaluar\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge Regression\": Ridge(alpha=1.0),\n",
    "    \"Lasso Regression\": Lasso(alpha=0.1),\n",
    "    \"Elastic Net Regression\": ElasticNet(alpha=0.1, l1_ratio=0.5),\n",
    "    \"K-Nearest Neighbors Regression\": KNeighborsRegressor(n_neighbors=5),\n",
    "    \"Random Forest Regression\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"XGBoost Regression\": XGBRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Evaluación de modelos\n",
    "results = {}\n",
    "best_model_name = None\n",
    "best_model = None\n",
    "best_r2_score = float('-inf')\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    results[model_name] = {\"R2 Score\": r2}\n",
    "    \n",
    "    # Verificar si este modelo tiene el mejor R2 score\n",
    "    if r2 > best_r2_score:\n",
    "        best_r2_score = r2\n",
    "        best_model = model\n",
    "        best_model_name = model_name\n",
    "\n",
    "# Imprimir los resultados de R2 para cada modelo\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"{model_name}: R2 Score = {metrics['R2 Score']:.4f}\")\n",
    "\n",
    "print(f\"\\nBest model: {best_model_name} with R2 Score = {best_r2_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: R2 Score = 0.9392, Best Params = {}\n",
      "Ridge Regression: R2 Score = 0.9444, Best Params = {'model__alpha': 10.0}\n",
      "Lasso Regression: R2 Score = 0.9339, Best Params = {'model__alpha': 0.01}\n",
      "Elastic Net Regression: R2 Score = 0.9435, Best Params = {'model__alpha': 0.01, 'model__l1_ratio': 0.2}\n",
      "K-Nearest Neighbors Regression: R2 Score = 0.5460, Best Params = {'model__n_neighbors': 10}\n",
      "Random Forest Regression: R2 Score = 0.8534, Best Params = {'model__max_depth': 20, 'model__n_estimators': 500}\n",
      "Gradient Boosting Regression: R2 Score = 0.8994, Best Params = {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__n_estimators': 500}\n",
      "XGBoost Regression: R2 Score = 0.9075, Best Params = {'model__learning_rate': 0.2, 'model__max_depth': 3, 'model__n_estimators': 500}\n",
      "Voting Regressor: R2 Score = 0.8855, Best Params = N/A\n",
      "Stacking Regressor: R2 Score = 0.8445, Best Params = N/A\n",
      "\n",
      "Best model: Ridge Regression with R2 Score = 0.9444\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_predict\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor, StackingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Cargar los datos\n",
    "file_path = '../data/Model_Data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Realizar codificación one-hot para la columna 'Country'\n",
    "data = pd.get_dummies(data, columns=['Country'], drop_first=True)\n",
    "\n",
    "# Separar las características (X) y la variable objetivo (y)\n",
    "X = data.drop(columns=['Happiness Score'])\n",
    "y = data['Happiness Score']\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Definir los modelos y sus hiperparámetros para la búsqueda\n",
    "models = {\n",
    "    \"Linear Regression\": {\n",
    "        \"model\": LinearRegression(),\n",
    "        \"params\": {}\n",
    "    },\n",
    "    \"Ridge Regression\": {\n",
    "        \"model\": Ridge(),\n",
    "        \"params\": {\"alpha\": [0.1, 1.0, 10.0]}\n",
    "    },\n",
    "    \"Lasso Regression\": {\n",
    "        \"model\": Lasso(),\n",
    "        \"params\": {\"alpha\": [0.01, 0.1, 1.0]}\n",
    "    },\n",
    "    \"Elastic Net Regression\": {\n",
    "        \"model\": ElasticNet(),\n",
    "        \"params\": {\"alpha\": [0.01, 0.1, 1.0], \"l1_ratio\": [0.2, 0.5, 0.8]}\n",
    "    },\n",
    "    \"K-Nearest Neighbors Regression\": {\n",
    "        \"model\": KNeighborsRegressor(),\n",
    "        \"params\": {\"n_neighbors\": [3, 5, 7, 10]}\n",
    "    },\n",
    "    \"Random Forest Regression\": {\n",
    "        \"model\": RandomForestRegressor(random_state=42),\n",
    "        \"params\": {\"n_estimators\": [200, 300, 500], \"max_depth\": [None, 10, 20]}\n",
    "    },\n",
    "    \"Gradient Boosting Regression\": {\n",
    "        \"model\": GradientBoostingRegressor(random_state=42),\n",
    "        \"params\": {\"n_estimators\": [200, 300, 500], \"learning_rate\": [0.05, 0.1, 0.2], \"max_depth\": [3, 5, 7]}\n",
    "    },\n",
    "    \"XGBoost Regression\": {\n",
    "        \"model\": XGBRegressor(random_state=42),\n",
    "        \"params\": {\"n_estimators\": [200, 300, 500], \"learning_rate\": [0.05, 0.1, 0.2], \"max_depth\": [3, 5, 7]}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Evaluación de modelos y búsqueda de hiperparámetros\n",
    "results = {}\n",
    "best_model_name = None\n",
    "best_model = None\n",
    "best_r2_score = float('-inf')\n",
    "\n",
    "for model_name, model_dict in models.items():\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),  # Solo escalado\n",
    "        ('model', model_dict[\"model\"])\n",
    "    ])\n",
    "    \n",
    "    # Configurar GridSearchCV con los hiperparámetros del modelo actual\n",
    "    grid = GridSearchCV(pipe, {'model__' + key: value for key, value in model_dict[\"params\"].items()},\n",
    "                        cv=5, scoring='r2', n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicciones y evaluación del modelo\n",
    "    y_pred = grid.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    results[model_name] = {\"R2 Score\": r2, \"Best Params\": grid.best_params_}\n",
    "    \n",
    "    # Guardar el mejor modelo según el R2 Score\n",
    "    if r2 > best_r2_score:\n",
    "        best_r2_score = r2\n",
    "        best_model = grid.best_estimator_\n",
    "        best_model_name = model_name\n",
    "\n",
    "# Prueba con VotingRegressor usando los mejores modelos\n",
    "voting_reg = VotingRegressor(estimators=[\n",
    "    ('KNN', KNeighborsRegressor(n_neighbors=3)),\n",
    "    ('RandomForest', RandomForestRegressor(n_estimators=300, max_depth=None, random_state=42)),\n",
    "    ('XGBoost', XGBRegressor(n_estimators=300, learning_rate=0.05, max_depth=5, random_state=42))\n",
    "])\n",
    "voting_reg.fit(X_train, y_train)\n",
    "y_pred_voting = voting_reg.predict(X_test)\n",
    "r2_voting = r2_score(y_test, y_pred_voting)\n",
    "\n",
    "# Prueba con StackingRegressor usando los mejores modelos\n",
    "stacking_reg = StackingRegressor(\n",
    "    estimators=[\n",
    "        ('KNN', KNeighborsRegressor(n_neighbors=3)),\n",
    "        ('RandomForest', RandomForestRegressor(n_estimators=300, max_depth=None, random_state=42)),\n",
    "        ('XGBoost', XGBRegressor(n_estimators=300, learning_rate=0.05, max_depth=5, random_state=42))\n",
    "    ],\n",
    "    final_estimator=GradientBoostingRegressor(n_estimators=300, learning_rate=0.05, max_depth=5, random_state=42)\n",
    ")\n",
    "stacking_reg.fit(X_train, y_train)\n",
    "y_pred_stacking = stacking_reg.predict(X_test)\n",
    "r2_stacking = r2_score(y_test, y_pred_stacking)\n",
    "\n",
    "# Agregar los resultados de VotingRegressor y StackingRegressor\n",
    "results[\"Voting Regressor\"] = {\"R2 Score\": r2_voting, \"Best Params\": \"N/A\"}\n",
    "results[\"Stacking Regressor\"] = {\"R2 Score\": r2_stacking, \"Best Params\": \"N/A\"}\n",
    "\n",
    "if r2_voting > best_r2_score:\n",
    "    best_r2_score = r2_voting\n",
    "    best_model = voting_reg\n",
    "    best_model_name = \"Voting Regressor\"\n",
    "\n",
    "if r2_stacking > best_r2_score:\n",
    "    best_r2_score = r2_stacking\n",
    "    best_model = stacking_reg\n",
    "    best_model_name = \"Stacking Regressor\"\n",
    "\n",
    "# Imprimir los resultados de R2 y los mejores parámetros para cada modelo\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"{model_name}: R2 Score = {metrics['R2 Score']:.4f}, Best Params = {metrics['Best Params']}\")\n",
    "\n",
    "print(f\"\\nBest model: {best_model_name} with R2 Score = {best_r2_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelo: Linear Regression\n",
      "R^2 Score: 0.9495858523063235\n",
      "\n",
      "Modelo: Random Forest\n",
      "R^2 Score: 0.8486986222615859\n",
      "\n",
      "Modelo: Gradient Boosting\n",
      "R^2 Score: 0.842152498124545\n",
      "\n",
      "Modelo: AdaBoost\n",
      "R^2 Score: 0.7726456924117253\n",
      "\n",
      "Modelo: Support Vector Regression\n",
      "R^2 Score: 0.9237282170578003\n",
      "\n",
      "Modelo: K-Nearest Neighbors\n",
      "R^2 Score: 0.8937572721799011\n",
      "\n",
      "Best model: Linear Regression with R2 Score = 0.9496\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Cargar los datos\n",
    "data = pd.read_csv('../data/Model_Data.csv')\n",
    "\n",
    "# Definir las características y la variable objetivo\n",
    "X = data.drop(columns=['Happiness Score'])\n",
    "y = data['Happiness Score']\n",
    "\n",
    "# Preprocesar los datos: aplicar One-Hot Encoding a la columna 'Country' y escalar el resto\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('country', OneHotEncoder(handle_unknown='ignore'), ['Country']),  # Codificar la columna 'Country' y manejar categorías desconocidas\n",
    "        ('num', SimpleImputer(strategy='mean'), X.columns.difference(['Country', 'Year']))  # Imputar valores faltantes para otras columnas numéricas\n",
    "    ])\n",
    "\n",
    "# Crear un diccionario de modelos\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
    "    'AdaBoost': AdaBoostRegressor(random_state=42),\n",
    "    'Support Vector Regression': SVR(),\n",
    "    'K-Nearest Neighbors': KNeighborsRegressor()\n",
    "}\n",
    "\n",
    "# Dividir los datos en entrenamiento y prueba (80% entrenamiento, 20% prueba)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Variables para almacenar el mejor modelo y su rendimiento\n",
    "best_model = None\n",
    "best_r2 = float('-inf')  # Inicializamos con el peor valor posible para R^2\n",
    "best_model_name = \"\"  # Para almacenar el nombre del mejor modelo\n",
    "\n",
    "# Entrenar y evaluar cada modelo\n",
    "for model_name, model in models.items():\n",
    "    # Crear un pipeline para cada modelo\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', model)\n",
    "    ])\n",
    "    \n",
    "    # Entrenar el modelo\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Hacer predicciones\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    # Evaluar el modelo\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f'\\nModelo: {model_name}')\n",
    "    print(f'R^2 Score: {r2}')\n",
    "    \n",
    "    # Si el modelo actual es el mejor, lo guardamos\n",
    "    if r2 > best_r2:\n",
    "        best_r2 = r2\n",
    "        best_model = pipeline\n",
    "        best_model_name = model_name\n",
    "\n",
    "print(f\"\\nBest model: {best_model_name} with R2 Score = {best_r2:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado exitosamente en 'Model/Regression_Model'\n"
     ]
    }
   ],
   "source": [
    "# Guardar el mejor modelo en un archivo .pkl\n",
    "with open('../Model/Regression_Model.pkl', 'wb') as file:\n",
    "    pickle.dump(best_model, file)\n",
    "\n",
    "print(\"Modelo guardado exitosamente en 'Model/Regression_Model'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
